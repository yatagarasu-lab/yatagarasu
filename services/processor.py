import os
from utils.file_utils import load_file_content
from utils.duplicate_checker import is_duplicate
from services.gpt_summarizer import summarize_text, analyze_text

# å‡¦ç†ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼šDropboxã‹ã‚‰å–å¾—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æ
def process_file(dbx, file_metadata, path_lower):
    print(f"ğŸ“„ å‡¦ç†é–‹å§‹: {path_lower}")

    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’å–å¾—
        file_content = load_file_content(dbx, path_lower)

        # é‡è¤‡ãƒã‚§ãƒƒã‚¯
        if is_duplicate(file_content):
            print(f"âš ï¸ é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰: {path_lower}")
            return {
                "status": "duplicate",
                "path": path_lower
            }

        # è¦ç´„
        summary = summarize_text(file_content)

        # è§£æ
        analysis = analyze_text(file_content)

        print("âœ… å‡¦ç†å®Œäº†")
        return {
            "status": "processed",
            "path": path_lower,
            "summary": summary,
            "analysis": analysis
        }

    except Exception as e:
        print(f"âŒ å‡¦ç†ä¸­ã‚¨ãƒ©ãƒ¼: {e}")
        return {
            "status": "error",
            "path": path_lower,
            "error": str(e)
        }
