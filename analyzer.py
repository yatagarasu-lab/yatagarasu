import openai
import pytesseract
from PIL import Image, ImageEnhance, ImageFilter
import io
import os

openai.api_key = os.getenv("OPENAI_API_KEY")

# ç”»åƒã®å‰å‡¦ç†
def preprocess_image(image_data):
    image = Image.open(image_data).convert("L")  # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«
    image = image.filter(ImageFilter.MedianFilter())
    enhancer = ImageEnhance.Contrast(image)
    image = enhancer.enhance(2.0)  # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·èª¿
    return image

# OCRã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
def extract_text(image):
    return pytesseract.image_to_string(image, lang="jpn")

# GPTã«ã‚ˆã‚‹è¦ç´„ï¼‹è¨­å®šæ¨æ¸¬
def summarize_text(text):
    prompt = f"""
ä»¥ä¸‹ã¯ã‚¹ãƒ­ãƒƒãƒˆã®ãƒ‡ãƒ¼ã‚¿ç”»åƒã‹ã‚‰æŠ½å‡ºã—ãŸãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚
å‡ºç¾ã—ã¦ã„ã‚‹ãƒ¯ãƒ¼ãƒ‰ã€è¨­å®šå·®ã®ã‚ã‚‹ã‚¾ãƒ¼ãƒ³ã€å³è‚©ä¸ŠãŒã‚Šã®è¡¨ç¾ã€ATå±¥æ­´ãªã©ã‹ã‚‰ã€å†…å®¹ã‚’è¦ç´„ã—ã€
é«˜è¨­å®šã®å¯èƒ½æ€§ãŒã‚ã‚‹ã‹ã‚’ã‚³ãƒ¡ãƒ³ãƒˆã—ã¦ãã ã•ã„ã€‚

ç‰¹ã«ä»¥ä¸‹ã®ç‚¹ã‚’é‡è¦–ã—ã¦ãã ã•ã„ï¼š
- ã€Œæœã‚«ã‚¹ã€ã€Œ1000ã‚«ã‚¹ã€ãªã©ã®è¨­å®šç¤ºå”†ãƒ¯ãƒ¼ãƒ‰
- CZå±¥æ­´ï¼ˆ150/250/450/650Gãªã©ï¼‰
- ã€Œå³è‚©ä¸ŠãŒã‚Šã€ã€Œ2000æšã€ã€Œå·®æšãƒ—ãƒ©ã‚¹ã€ãªã©ã®è‰¯æŒ™å‹•
- ã‚°ãƒ©ãƒ•ã®é›°å›²æ°—ï¼ˆä¾‹ï¼šå‚ç›´ã€Vå­—ã€å®‰å®šï¼‰

ã€OCRæŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆã€‘
{text}
"""

    response = openai.ChatCompletion.create(
        model="gpt-4",
        temperature=0.3,
        messages=[
            {"role": "system", "content": "ã‚¹ãƒ­ãƒƒãƒˆå°ã®è¨­å®šæ¨æ¸¬ã‚¢ãƒŠãƒªã‚¹ãƒˆã¨ã—ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚"},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message["content"]

# ç”»åƒãƒ‡ãƒ¼ã‚¿1æšã‚’å‡¦ç†ã—ã¦è¦ç´„è¿”å´
def analyze_file(filename, image_data):
    try:
        image = preprocess_image(image_data)
        text = extract_text(image)
        summary = summarize_text(text)
        return f"ğŸ“„ {filename}:\n{summary}"
    except Exception as e:
        return f"âš ï¸ {filename}: è§£æã‚¨ãƒ©ãƒ¼ - {str(e)}"