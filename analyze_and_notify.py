import json
from dropbox_handler import list_files, download_file, file_hash, delete_file
from line_notify import send_line_message

analyzed_hashes = set()

# ğŸ” â‘  æœ€åˆã«é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦å‰Šé™¤ã™ã‚‹
def find_and_remove_duplicates(folder_path="/Apps/slot-data-analyzer"):
    files = list_files(folder_path)
    hash_map = {}

    for file in files:
        path = file.path_display
        content = download_file(path)
        hash_value = file_hash(content)

        if hash_value in hash_map:
            print(f"âš ï¸ é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º: {path}ï¼ˆåŒä¸€: {hash_map[hash_value]}ï¼‰")
            delete_file(path)
        else:
            hash_map[hash_value] = path

# ğŸ§  â‘¡ ãƒ†ã‚­ã‚¹ãƒˆã®è¦ç´„å‡¦ç†
def summarize_text(text):
    lines = text.splitlines()
    summary = "\n".join(lines[:5])  # æœ€åˆã®5è¡Œã ã‘é€šçŸ¥
    return summary

# ğŸ” â‘¢ æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã¦LINEé€šçŸ¥
def analyze_new_files():
    files = list_files()
    for file in files:
        if not file.name.endswith(".txt"):
            continue

        content = download_file(file.path_display)
        hash_val = file_hash(content)

        if hash_val in analyzed_hashes:
            continue

        analyzed_hashes.add(hash_val)
        text = content.decode("utf-8")
        summary = summarize_text(text)
        send_line_message(f"ğŸ“¦ æ–°ã—ã„è§£æçµæœ:\n\n{summary}")